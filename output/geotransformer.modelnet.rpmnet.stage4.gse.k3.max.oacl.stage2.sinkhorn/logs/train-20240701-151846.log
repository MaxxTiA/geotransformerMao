[2024-07-01 15:18:46] [INFO] Command executed: E:/GeoTransformer-1.0.0/experiments/geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn/trainval.py
[2024-07-01 15:18:46] [INFO] Configs:
{
    "seed": 7351,
    "working_dir": "E:\\GeoTransformer-1.0.0\\experiments\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "root_dir": "E:\\GeoTransformer-1.0.0",
    "exp_name": "geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "output_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "snapshot_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\snapshots",
    "log_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\logs",
    "event_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\events",
    "data": {
        "dataset_root": "E:\\GeoTransformer-1.0.0\\data\\ModelNet",
        "num_points": 717,
        "voxel_size": null,
        "rotation_magnitude": 180.0,
        "translation_magnitude": 0.5,
        "keep_ratio": 0.7,
        "crop_method": "plane",
        "asymmetric": true,
        "twice_sample": true,
        "twice_transform": false
    },
    "train": {
        "batch_size": 1,
        "num_workers": 8,
        "noise_magnitude": 0.05,
        "class_indices": "all"
    },
    "test": {
        "batch_size": 1,
        "num_workers": 8,
        "noise_magnitude": 0.05,
        "class_indices": "all"
    },
    "eval": {
        "acceptance_overlap": 0.0,
        "acceptance_radius": 0.1,
        "inlier_ratio_threshold": 0.05,
        "rre_threshold": 1.0,
        "rte_threshold": 0.1
    },
    "ransac": {
        "distance_threshold": 0.05,
        "num_points": 3,
        "num_iterations": 1000
    },
    "optim": {
        "lr": 0.0001,
        "weight_decay": 1e-06,
        "warmup_steps": 10000,
        "eta_init": 0.1,
        "eta_min": 0.1,
        "max_iteration": 400000,
        "snapshot_steps": 10000,
        "grad_acc_steps": 1
    },
    "backbone": {
        "num_stages": 3,
        "init_voxel_size": 0.05,
        "kernel_size": 15,
        "base_radius": 2.5,
        "base_sigma": 2.0,
        "init_radius": 0.125,
        "init_sigma": 0.1,
        "group_norm": 32,
        "input_dim": 1,
        "init_dim": 64,
        "output_dim": 256
    },
    "model": {
        "ground_truth_matching_radius": 0.05,
        "num_points_in_patch": 128,
        "num_sinkhorn_iterations": 100
    },
    "coarse_matching": {
        "num_targets": 128,
        "overlap_threshold": 0.1,
        "num_correspondences": 128,
        "dual_normalization": true
    },
    "geotransformer": {
        "input_dim": 512,
        "hidden_dim": 256,
        "output_dim": 256,
        "num_heads": 4,
        "blocks": [
            "self",
            "cross",
            "self",
            "cross",
            "self",
            "cross"
        ],
        "sigma_d": 0.2,
        "sigma_a": 15,
        "angle_k": 3,
        "reduction_a": "max"
    },
    "fine_matching": {
        "topk": 3,
        "acceptance_radius": 0.1,
        "mutual": true,
        "confidence_threshold": 0.05,
        "use_dustbin": false,
        "use_global_score": false,
        "correspondence_threshold": 3,
        "correspondence_limit": null,
        "num_refinement_steps": 5
    },
    "coarse_loss": {
        "positive_margin": 0.1,
        "negative_margin": 1.4,
        "positive_optimal": 0.1,
        "negative_optimal": 1.4,
        "log_scale": 24,
        "positive_overlap": 0.1
    },
    "fine_loss": {
        "positive_radius": 0.05
    },
    "loss": {
        "weight_coarse_loss": 1.0,
        "weight_fine_loss": 1.0
    }
}
[2024-07-01 15:18:46] [INFO] Tensorboard is enabled. Write events to E:\GeoTransformer-1.0.0\output\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\events.
[2024-07-01 15:18:46] [INFO] Using Single-GPU mode.
[2024-07-01 15:18:46] [INFO] Data loader created: 0.613s collapsed.
[2024-07-01 15:18:46] [INFO] Calibrate neighbors: [27 32 35].
[2024-07-01 15:18:48] [INFO] Model description:
GeoTransformer(
  (backbone): KPConvFPN(
    (encoder1_1): ConvBlock(
      (KPConv): KPConv(kernel_size: 15, in_channels: 1, out_channels: 64, radius: 0.125, sigma: 0.1, bias: True)
      (norm): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder1_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=32, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 32, out_channels: 32, radius: 0.125, sigma: 0.1, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=32, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_1): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=32, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 32, out_channels: 32, radius: 0.125, sigma: 0.1, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=32, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_3): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_1): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 128, out_channels: 128, radius: 0.5, sigma: 0.4, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_3): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=512, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 128, out_channels: 128, radius: 0.5, sigma: 0.4, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (decoder2): UnaryBlock(
      (mlp): Linear(in_features=768, out_features=256, bias=True)
      (norm): GroupNorm(
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (decoder1): LastUnaryBlock(
      (mlp): Linear(in_features=384, out_features=256, bias=True)
    )
  )
  (transformer): GeometricTransformer(
    (embedding): GeometricStructureEmbedding(
      (embedding): SinusoidalPositionalEmbedding()
      (proj_d): Linear(in_features=256, out_features=256, bias=True)
      (proj_a): Linear(in_features=256, out_features=256, bias=True)
    )
    (in_proj): Linear(in_features=512, out_features=256, bias=True)
    (transformer): RPEConditionalTransformer(
      (layers): ModuleList(
        (0): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (out_proj): Linear(in_features=256, out_features=256, bias=True)
  )
  (coarse_target): SuperPointTargetGenerator()
  (coarse_matching): SuperPointMatching()
  (fine_matching): LocalGlobalRegistration(
    (procrustes): WeightedProcrustes()
  )
  (optimal_transport): LearnableLogOptimalTransport(num_iterations=100)
)
[2024-07-01 15:19:13] [INFO] Iter: 10/400000, loss: 2.512, c_loss: 1.052, f_loss: 1.460, PIR: 0.046, IR: 0.329, RRE: 52.149, RTE: 0.424, RMSE: 0.319, RR: 0.000, lr: 1.009e-05, time: 2.149s/0.427s
[2024-07-01 15:19:17] [INFO] Iter: 20/400000, loss: 2.416, c_loss: 0.982, f_loss: 1.433, PIR: 0.043, IR: 0.315, RRE: 38.194, RTE: 0.188, RMSE: 0.207, RR: 0.100, lr: 1.018e-05, time: 1.092s/0.367s
[2024-07-01 15:19:20] [INFO] Iter: 30/400000, loss: 2.458, c_loss: 0.989, f_loss: 1.469, PIR: 0.048, IR: 0.325, RRE: 7.615, RTE: 0.077, RMSE: 0.076, RR: 0.100, lr: 1.027e-05, time: 0.739s/0.343s
[2024-07-01 15:19:23] [INFO] Iter: 40/400000, loss: 2.406, c_loss: 0.952, f_loss: 1.454, PIR: 0.058, IR: 0.356, RRE: 34.157, RTE: 0.238, RMSE: 0.266, RR: 0.000, lr: 1.036e-05, time: 0.562s/0.332s
[2024-07-01 15:19:27] [INFO] Iter: 50/400000, loss: 2.490, c_loss: 0.947, f_loss: 1.542, PIR: 0.070, IR: 0.359, RRE: 51.915, RTE: 0.401, RMSE: 0.374, RR: 0.000, lr: 1.045e-05, time: 0.456s/0.326s
[2024-07-01 15:19:30] [INFO] Iter: 60/400000, loss: 2.584, c_loss: 0.940, f_loss: 1.644, PIR: 0.076, IR: 0.388, RRE: 47.875, RTE: 0.387, RMSE: 0.290, RR: 0.000, lr: 1.054e-05, time: 0.386s/0.322s
[2024-07-01 15:19:33] [INFO] Iter: 70/400000, loss: 2.378, c_loss: 0.935, f_loss: 1.442, PIR: 0.070, IR: 0.345, RRE: 28.583, RTE: 0.138, RMSE: 0.203, RR: 0.000, lr: 1.063e-05, time: 0.335s/0.318s
[2024-07-01 15:19:37] [INFO] Iter: 80/400000, loss: 2.354, c_loss: 0.939, f_loss: 1.415, PIR: 0.050, IR: 0.350, RRE: 40.610, RTE: 0.353, RMSE: 0.373, RR: 0.000, lr: 1.072e-05, time: 0.297s/0.316s
[2024-07-01 15:19:40] [INFO] Iter: 90/400000, loss: 2.426, c_loss: 0.930, f_loss: 1.496, PIR: 0.064, IR: 0.402, RRE: 36.381, RTE: 0.228, RMSE: 0.120, RR: 0.100, lr: 1.081e-05, time: 0.268s/0.314s
[2024-07-01 15:19:43] [INFO] Iter: 100/400000, loss: 2.387, c_loss: 0.929, f_loss: 1.458, PIR: 0.095, IR: 0.392, RRE: 21.091, RTE: 0.159, RMSE: 0.122, RR: 0.100, lr: 1.090e-05, time: 0.245s/0.312s
[2024-07-01 15:19:47] [INFO] Iter: 110/400000, loss: 2.461, c_loss: 0.923, f_loss: 1.538, PIR: 0.073, IR: 0.348, RRE: 25.750, RTE: 0.199, RMSE: 0.202, RR: 0.000, lr: 1.099e-05, time: 0.225s/0.311s
