[2024-07-09 13:02:08] [INFO] Command executed: trainval.py
[2024-07-09 13:02:08] [INFO] Configs:
{
    "seed": 7351,
    "working_dir": "E:\\GeoTransformer-1.0.0\\experiments\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "root_dir": "E:\\GeoTransformer-1.0.0",
    "exp_name": "geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "output_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "snapshot_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\snapshots",
    "log_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\logs",
    "event_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\events",
    "data": {
        "dataset_root": "E:\\GeoTransformer-1.0.0\\data\\ModelNet",
        "num_points": 717,
        "voxel_size": null,
        "rotation_magnitude": 180.0,
        "translation_magnitude": 0.5,
        "keep_ratio": 0.7,
        "crop_method": "plane",
        "asymmetric": true,
        "twice_sample": true,
        "twice_transform": false
    },
    "train": {
        "batch_size": 1,
        "num_workers": 8,
        "noise_magnitude": 0.05,
        "class_indices": "all"
    },
    "test": {
        "batch_size": 1,
        "num_workers": 8,
        "noise_magnitude": 0.05,
        "class_indices": "all"
    },
    "eval": {
        "acceptance_overlap": 0.0,
        "acceptance_radius": 0.1,
        "inlier_ratio_threshold": 0.05,
        "rre_threshold": 1.0,
        "rte_threshold": 0.1
    },
    "ransac": {
        "distance_threshold": 0.05,
        "num_points": 3,
        "num_iterations": 1000
    },
    "optim": {
        "lr": 0.0001,
        "weight_decay": 1e-06,
        "warmup_steps": 10000,
        "eta_init": 0.1,
        "eta_min": 0.1,
        "max_iteration": 400000,
        "snapshot_steps": 10000,
        "grad_acc_steps": 1
    },
    "backbone": {
        "num_stages": 3,
        "init_voxel_size": 0.05,
        "kernel_size": 15,
        "base_radius": 2.5,
        "base_sigma": 2.0,
        "init_radius": 0.125,
        "init_sigma": 0.1,
        "group_norm": 32,
        "input_dim": 1,
        "init_dim": 64,
        "output_dim": 256
    },
    "model": {
        "ground_truth_matching_radius": 0.05,
        "num_points_in_patch": 128,
        "num_sinkhorn_iterations": 100
    },
    "coarse_matching": {
        "num_targets": 128,
        "overlap_threshold": 0.1,
        "num_correspondences": 128,
        "dual_normalization": true
    },
    "geotransformer": {
        "input_dim": 512,
        "hidden_dim": 256,
        "output_dim": 256,
        "num_heads": 4,
        "blocks": [
            "self",
            "cross",
            "self",
            "cross",
            "self",
            "cross"
        ],
        "sigma_d": 0.2,
        "sigma_a": 15,
        "angle_k": 3,
        "reduction_a": "max"
    },
    "fine_matching": {
        "topk": 3,
        "acceptance_radius": 0.1,
        "mutual": true,
        "confidence_threshold": 0.05,
        "use_dustbin": false,
        "use_global_score": false,
        "correspondence_threshold": 3,
        "correspondence_limit": null,
        "num_refinement_steps": 5
    },
    "coarse_loss": {
        "positive_margin": 0.1,
        "negative_margin": 1.4,
        "positive_optimal": 0.1,
        "negative_optimal": 1.4,
        "log_scale": 24,
        "positive_overlap": 0.1
    },
    "fine_loss": {
        "positive_radius": 0.05
    },
    "loss": {
        "weight_coarse_loss": 1.0,
        "weight_fine_loss": 1.0
    }
}
[2024-07-09 13:02:08] [INFO] Tensorboard is enabled. Write events to E:\GeoTransformer-1.0.0\output\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\events.
[2024-07-09 13:02:08] [INFO] Using Single-GPU mode.
[2024-07-09 13:02:08] [INFO] Data loader created: 0.599s collapsed.
[2024-07-09 13:02:08] [INFO] Calibrate neighbors: [27 32 35].
[2024-07-09 13:02:10] [INFO] Model description:
GeoTransformer(
  (backbone): KPConvFPN(
    (encoder1_1): ConvBlock(
      (KPConv): KPConv(kernel_size: 15, in_channels: 1, out_channels: 64, radius: 0.125, sigma: 0.1, bias: True)
      (norm): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder1_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=32, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 32, out_channels: 32, radius: 0.125, sigma: 0.1, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=32, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_1): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=32, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 32, out_channels: 32, radius: 0.125, sigma: 0.1, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=32, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_3): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_1): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 128, out_channels: 128, radius: 0.5, sigma: 0.4, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_3): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=512, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 128, out_channels: 128, radius: 0.5, sigma: 0.4, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (decoder2): UnaryBlock(
      (mlp): Linear(in_features=768, out_features=256, bias=True)
      (norm): GroupNorm(
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (decoder1): LastUnaryBlock(
      (mlp): Linear(in_features=384, out_features=256, bias=True)
    )
  )
  (transformer): GeometricTransformer(
    (embedding): GeometricStructureEmbedding(
      (embedding): SinusoidalPositionalEmbedding()
      (proj_d): Linear(in_features=256, out_features=256, bias=True)
      (proj_a): Linear(in_features=256, out_features=256, bias=True)
    )
    (in_proj): Linear(in_features=512, out_features=256, bias=True)
    (transformer): RPEConditionalTransformer(
      (layers): ModuleList(
        (0): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (out_proj): Linear(in_features=256, out_features=256, bias=True)
  )
  (coarse_target): SuperPointTargetGenerator()
  (coarse_matching): SuperPointMatching()
  (fine_matching): LocalGlobalRegistration(
    (procrustes): WeightedProcrustes()
  )
  (optimal_transport): LearnableLogOptimalTransport(num_iterations=100)
)
[2024-07-09 13:02:35] [INFO] Iter: 10/400000, loss: 2.512, c_loss: 1.052, f_loss: 1.460, PIR: 0.046, IR: 0.329, RRE: 52.590, RTE: 0.421, RMSE: 0.318, RR: 0.000, lr: 1.009e-05, time: 2.128s/0.437s
[2024-07-09 13:02:39] [INFO] Iter: 20/400000, loss: 2.416, c_loss: 0.983, f_loss: 1.433, PIR: 0.041, IR: 0.315, RRE: 37.358, RTE: 0.244, RMSE: 0.218, RR: 0.200, lr: 1.018e-05, time: 1.081s/0.369s
[2024-07-09 13:02:42] [INFO] Iter: 30/400000, loss: 2.458, c_loss: 0.989, f_loss: 1.469, PIR: 0.048, IR: 0.325, RRE: 7.761, RTE: 0.073, RMSE: 0.067, RR: 0.100, lr: 1.027e-05, time: 0.732s/0.346s
[2024-07-09 13:02:45] [INFO] Iter: 40/400000, loss: 2.406, c_loss: 0.952, f_loss: 1.454, PIR: 0.059, IR: 0.356, RRE: 33.511, RTE: 0.224, RMSE: 0.259, RR: 0.000, lr: 1.036e-05, time: 0.557s/0.334s
[2024-07-09 13:02:49] [INFO] Iter: 50/400000, loss: 2.490, c_loss: 0.947, f_loss: 1.542, PIR: 0.070, IR: 0.359, RRE: 52.030, RTE: 0.402, RMSE: 0.374, RR: 0.000, lr: 1.045e-05, time: 0.452s/0.327s
[2024-07-09 13:02:52] [INFO] Iter: 60/400000, loss: 2.584, c_loss: 0.939, f_loss: 1.644, PIR: 0.077, IR: 0.389, RRE: 48.153, RTE: 0.389, RMSE: 0.288, RR: 0.000, lr: 1.054e-05, time: 0.382s/0.321s
[2024-07-09 13:02:55] [INFO] Iter: 70/400000, loss: 2.378, c_loss: 0.935, f_loss: 1.442, PIR: 0.071, IR: 0.344, RRE: 16.293, RTE: 0.113, RMSE: 0.101, RR: 0.100, lr: 1.063e-05, time: 0.332s/0.318s
[2024-07-09 13:02:59] [INFO] Iter: 80/400000, loss: 2.354, c_loss: 0.939, f_loss: 1.415, PIR: 0.049, IR: 0.350, RRE: 40.848, RTE: 0.354, RMSE: 0.376, RR: 0.000, lr: 1.072e-05, time: 0.295s/0.316s
[2024-07-09 13:03:02] [INFO] Iter: 90/400000, loss: 2.426, c_loss: 0.930, f_loss: 1.496, PIR: 0.063, IR: 0.401, RRE: 36.119, RTE: 0.226, RMSE: 0.119, RR: 0.100, lr: 1.081e-05, time: 0.266s/0.314s
[2024-07-09 13:03:05] [INFO] Iter: 100/400000, loss: 2.387, c_loss: 0.929, f_loss: 1.458, PIR: 0.091, IR: 0.392, RRE: 19.573, RTE: 0.162, RMSE: 0.118, RR: 0.100, lr: 1.090e-05, time: 0.243s/0.313s
[2024-07-09 13:03:09] [INFO] Iter: 110/400000, loss: 2.461, c_loss: 0.923, f_loss: 1.538, PIR: 0.074, IR: 0.349, RRE: 29.348, RTE: 0.209, RMSE: 0.234, RR: 0.000, lr: 1.099e-05, time: 0.224s/0.311s
[2024-07-09 13:03:12] [INFO] Iter: 120/400000, loss: 2.408, c_loss: 0.929, f_loss: 1.479, PIR: 0.074, IR: 0.393, RRE: 11.101, RTE: 0.078, RMSE: 0.058, RR: 0.100, lr: 1.108e-05, time: 0.208s/0.310s
[2024-07-09 13:03:15] [INFO] Iter: 130/400000, loss: 2.173, c_loss: 0.911, f_loss: 1.263, PIR: 0.059, IR: 0.323, RRE: 26.767, RTE: 0.201, RMSE: 0.240, RR: 0.000, lr: 1.117e-05, time: 0.195s/0.309s
[2024-07-09 13:03:19] [INFO] Iter: 140/400000, loss: 2.150, c_loss: 0.911, f_loss: 1.238, PIR: 0.071, IR: 0.323, RRE: 9.641, RTE: 0.082, RMSE: 0.083, RR: 0.100, lr: 1.126e-05, time: 0.183s/0.308s
[2024-07-09 13:03:22] [INFO] Iter: 150/400000, loss: 2.526, c_loss: 0.925, f_loss: 1.601, PIR: 0.070, IR: 0.383, RRE: 31.823, RTE: 0.169, RMSE: 0.180, RR: 0.000, lr: 1.135e-05, time: 0.173s/0.307s
[2024-07-09 13:03:25] [INFO] Iter: 160/400000, loss: 2.423, c_loss: 0.919, f_loss: 1.504, PIR: 0.045, IR: 0.396, RRE: 29.127, RTE: 0.210, RMSE: 0.144, RR: 0.000, lr: 1.144e-05, time: 0.164s/0.307s
