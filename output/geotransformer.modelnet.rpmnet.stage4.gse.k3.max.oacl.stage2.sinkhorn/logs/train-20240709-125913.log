[2024-07-09 12:59:13] [INFO] Command executed: trainval.py
[2024-07-09 12:59:13] [INFO] Configs:
{
    "seed": 7351,
    "working_dir": "E:\\GeoTransformer-1.0.0\\experiments\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "root_dir": "E:\\GeoTransformer-1.0.0",
    "exp_name": "geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "output_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn",
    "snapshot_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\snapshots",
    "log_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\logs",
    "event_dir": "E:\\GeoTransformer-1.0.0\\output\\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\\events",
    "data": {
        "dataset_root": "E:\\GeoTransformer-1.0.0\\data\\ModelNet",
        "num_points": 717,
        "voxel_size": null,
        "rotation_magnitude": 180.0,
        "translation_magnitude": 0.5,
        "keep_ratio": 0.7,
        "crop_method": "plane",
        "asymmetric": true,
        "twice_sample": true,
        "twice_transform": false
    },
    "train": {
        "batch_size": 1,
        "num_workers": 8,
        "noise_magnitude": 0.05,
        "class_indices": "all"
    },
    "test": {
        "batch_size": 1,
        "num_workers": 8,
        "noise_magnitude": 0.05,
        "class_indices": "all"
    },
    "eval": {
        "acceptance_overlap": 0.0,
        "acceptance_radius": 0.1,
        "inlier_ratio_threshold": 0.05,
        "rre_threshold": 1.0,
        "rte_threshold": 0.1
    },
    "ransac": {
        "distance_threshold": 0.05,
        "num_points": 3,
        "num_iterations": 1000
    },
    "optim": {
        "lr": 0.0001,
        "weight_decay": 1e-06,
        "warmup_steps": 10000,
        "eta_init": 0.1,
        "eta_min": 0.1,
        "max_iteration": 400000,
        "snapshot_steps": 10000,
        "grad_acc_steps": 1
    },
    "backbone": {
        "num_stages": 3,
        "init_voxel_size": 0.05,
        "kernel_size": 15,
        "base_radius": 2.5,
        "base_sigma": 2.0,
        "init_radius": 0.125,
        "init_sigma": 0.1,
        "group_norm": 32,
        "input_dim": 1,
        "init_dim": 64,
        "output_dim": 256
    },
    "model": {
        "ground_truth_matching_radius": 0.05,
        "num_points_in_patch": 128,
        "num_sinkhorn_iterations": 100
    },
    "coarse_matching": {
        "num_targets": 128,
        "overlap_threshold": 0.1,
        "num_correspondences": 128,
        "dual_normalization": true
    },
    "geotransformer": {
        "input_dim": 512,
        "hidden_dim": 256,
        "output_dim": 256,
        "num_heads": 4,
        "blocks": [
            "self",
            "cross",
            "self",
            "cross",
            "self",
            "cross"
        ],
        "sigma_d": 0.2,
        "sigma_a": 15,
        "angle_k": 3,
        "reduction_a": "max"
    },
    "fine_matching": {
        "topk": 3,
        "acceptance_radius": 0.1,
        "mutual": true,
        "confidence_threshold": 0.05,
        "use_dustbin": false,
        "use_global_score": false,
        "correspondence_threshold": 3,
        "correspondence_limit": null,
        "num_refinement_steps": 5
    },
    "coarse_loss": {
        "positive_margin": 0.1,
        "negative_margin": 1.4,
        "positive_optimal": 0.1,
        "negative_optimal": 1.4,
        "log_scale": 24,
        "positive_overlap": 0.1
    },
    "fine_loss": {
        "positive_radius": 0.05
    },
    "loss": {
        "weight_coarse_loss": 1.0,
        "weight_fine_loss": 1.0
    }
}
[2024-07-09 12:59:13] [INFO] Tensorboard is enabled. Write events to E:\GeoTransformer-1.0.0\output\geotransformer.modelnet.rpmnet.stage4.gse.k3.max.oacl.stage2.sinkhorn\events.
[2024-07-09 12:59:13] [INFO] Using Single-GPU mode.
[2024-07-09 12:59:14] [INFO] Data loader created: 0.607s collapsed.
[2024-07-09 12:59:14] [INFO] Calibrate neighbors: [27 32 35].
[2024-07-09 12:59:15] [INFO] Model description:
GeoTransformer(
  (backbone): KPConvFPN(
    (encoder1_1): ConvBlock(
      (KPConv): KPConv(kernel_size: 15, in_channels: 1, out_channels: 64, radius: 0.125, sigma: 0.1, bias: True)
      (norm): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder1_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=32, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 32, out_channels: 32, radius: 0.125, sigma: 0.1, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=32, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_1): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=32, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 32, out_channels: 32, radius: 0.125, sigma: 0.1, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 32, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=32, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder2_3): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_1): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=64, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 64, out_channels: 64, radius: 0.25, sigma: 0.2, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 64, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=64, out_features=256, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_2): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 128, out_channels: 128, radius: 0.5, sigma: 0.4, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): UnaryBlock(
        (mlp): Linear(in_features=256, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (encoder3_3): ResidualBlock(
      (unary1): UnaryBlock(
        (mlp): Linear(in_features=512, out_features=128, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (KPConv): KPConv(kernel_size: 15, in_channels: 128, out_channels: 128, radius: 0.5, sigma: 0.4, bias: True)
      (norm_conv): GroupNorm(
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (unary2): UnaryBlock(
        (mlp): Linear(in_features=128, out_features=512, bias=True)
        (norm): GroupNorm(
          (norm): GroupNorm(32, 512, eps=1e-05, affine=True)
        )
      )
      (unary_shortcut): Identity()
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (decoder2): UnaryBlock(
      (mlp): Linear(in_features=768, out_features=256, bias=True)
      (norm): GroupNorm(
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (leaky_relu): LeakyReLU(negative_slope=0.1)
    )
    (decoder1): LastUnaryBlock(
      (mlp): Linear(in_features=384, out_features=256, bias=True)
    )
  )
  (transformer): GeometricTransformer(
    (embedding): GeometricStructureEmbedding(
      (embedding): SinusoidalPositionalEmbedding()
      (proj_d): Linear(in_features=256, out_features=256, bias=True)
      (proj_a): Linear(in_features=256, out_features=256, bias=True)
    )
    (in_proj): Linear(in_features=512, out_features=256, bias=True)
    (transformer): RPEConditionalTransformer(
      (layers): ModuleList(
        (0): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): RPETransformerLayer(
          (attention): RPEAttentionLayer(
            (attention): RPEMultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (proj_p): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): TransformerLayer(
          (attention): AttentionLayer(
            (attention): MultiHeadAttention(
              (proj_q): Linear(in_features=256, out_features=256, bias=True)
              (proj_k): Linear(in_features=256, out_features=256, bias=True)
              (proj_v): Linear(in_features=256, out_features=256, bias=True)
              (dropout): Identity()
            )
            (linear): Linear(in_features=256, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
          (output): AttentionOutput(
            (expand): Linear(in_features=256, out_features=512, bias=True)
            (activation): ReLU()
            (squeeze): Linear(in_features=512, out_features=256, bias=True)
            (dropout): Identity()
            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (out_proj): Linear(in_features=256, out_features=256, bias=True)
  )
  (coarse_target): SuperPointTargetGenerator()
  (coarse_matching): SuperPointMatching()
  (fine_matching): LocalGlobalRegistration(
    (procrustes): WeightedProcrustes()
  )
  (optimal_transport): LearnableLogOptimalTransport(num_iterations=100)
)
[2024-07-09 12:59:41] [INFO] Iter: 10/400000, loss: 2.512, c_loss: 1.052, f_loss: 1.460, PIR: 0.046, IR: 0.329, RRE: 52.189, RTE: 0.424, RMSE: 0.320, RR: 0.000, lr: 1.009e-05, time: 2.172s/0.451s
[2024-07-09 12:59:45] [INFO] Iter: 20/400000, loss: 2.416, c_loss: 0.982, f_loss: 1.433, PIR: 0.043, IR: 0.314, RRE: 38.253, RTE: 0.187, RMSE: 0.216, RR: 0.200, lr: 1.018e-05, time: 1.104s/0.381s
[2024-07-09 12:59:48] [INFO] Iter: 30/400000, loss: 2.457, c_loss: 0.989, f_loss: 1.469, PIR: 0.048, IR: 0.325, RRE: 8.078, RTE: 0.075, RMSE: 0.068, RR: 0.100, lr: 1.027e-05, time: 0.747s/0.358s
[2024-07-09 12:59:52] [INFO] Iter: 40/400000, loss: 2.406, c_loss: 0.952, f_loss: 1.454, PIR: 0.057, IR: 0.356, RRE: 32.900, RTE: 0.226, RMSE: 0.256, RR: 0.000, lr: 1.036e-05, time: 0.569s/0.345s
[2024-07-09 12:59:55] [INFO] Iter: 50/400000, loss: 2.490, c_loss: 0.947, f_loss: 1.542, PIR: 0.070, IR: 0.359, RRE: 52.125, RTE: 0.402, RMSE: 0.375, RR: 0.000, lr: 1.045e-05, time: 0.462s/0.338s
[2024-07-09 12:59:59] [INFO] Iter: 60/400000, loss: 2.584, c_loss: 0.939, f_loss: 1.644, PIR: 0.076, IR: 0.388, RRE: 47.822, RTE: 0.387, RMSE: 0.290, RR: 0.000, lr: 1.054e-05, time: 0.390s/0.335s
[2024-07-09 13:00:02] [INFO] Iter: 70/400000, loss: 2.378, c_loss: 0.936, f_loss: 1.442, PIR: 0.068, IR: 0.344, RRE: 27.080, RTE: 0.203, RMSE: 0.152, RR: 0.100, lr: 1.063e-05, time: 0.340s/0.331s
[2024-07-09 13:00:06] [INFO] Iter: 80/400000, loss: 2.354, c_loss: 0.939, f_loss: 1.415, PIR: 0.049, IR: 0.350, RRE: 23.851, RTE: 0.224, RMSE: 0.167, RR: 0.000, lr: 1.072e-05, time: 0.301s/0.329s
[2024-07-09 13:00:09] [INFO] Iter: 90/400000, loss: 2.426, c_loss: 0.930, f_loss: 1.496, PIR: 0.063, IR: 0.402, RRE: 36.045, RTE: 0.227, RMSE: 0.120, RR: 0.100, lr: 1.081e-05, time: 0.272s/0.328s
[2024-07-09 13:00:13] [INFO] Iter: 100/400000, loss: 2.387, c_loss: 0.929, f_loss: 1.458, PIR: 0.095, IR: 0.391, RRE: 30.912, RTE: 0.162, RMSE: 0.167, RR: 0.100, lr: 1.090e-05, time: 0.248s/0.326s
[2024-07-09 13:00:16] [INFO] Iter: 110/400000, loss: 2.461, c_loss: 0.923, f_loss: 1.538, PIR: 0.072, IR: 0.349, RRE: 25.695, RTE: 0.196, RMSE: 0.202, RR: 0.000, lr: 1.099e-05, time: 0.229s/0.326s
[2024-07-09 13:00:20] [INFO] Iter: 120/400000, loss: 2.408, c_loss: 0.929, f_loss: 1.479, PIR: 0.073, IR: 0.393, RRE: 10.087, RTE: 0.068, RMSE: 0.048, RR: 0.200, lr: 1.108e-05, time: 0.213s/0.326s
[2024-07-09 13:00:24] [INFO] Iter: 130/400000, loss: 2.173, c_loss: 0.911, f_loss: 1.263, PIR: 0.059, IR: 0.324, RRE: 25.516, RTE: 0.195, RMSE: 0.227, RR: 0.100, lr: 1.117e-05, time: 0.199s/0.327s
